{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23048c80",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d776bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# SHAP for interpretability\n",
    "import shap\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"SHAP version: {shap.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a467ed",
   "metadata": {},
   "source": [
    "## 2. Load Best Model and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa8d831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model comparison results to identify best model\n",
    "results_df = pd.read_csv('../models/model_comparison_results.csv')\n",
    "best_model_name = results_df.loc[results_df['Test RMSE'].idxmin(), 'Model']\n",
    "\n",
    "print(f\"Best Model: {best_model_name}\")\n",
    "print(f\"Test RMSE: {results_df['Test RMSE'].min():.4f}\")\n",
    "print(f\"Test R²: {results_df.loc[results_df['Test RMSE'].idxmin(), 'Test R2']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061ee0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine which dataset the best model uses\n",
    "linear_models = ['Ridge Regression', 'Lasso Regression', 'ElasticNet']\n",
    "catboost_models = ['CatBoost']\n",
    "\n",
    "if best_model_name in linear_models:\n",
    "    dataset_path = '../data/data_processed/dataset_linear_models.pkl'\n",
    "    model_file = best_model_name.lower().replace(' ', '_')\n",
    "elif best_model_name in catboost_models:\n",
    "    dataset_path = '../data/data_processed/dataset_catboost.pkl'\n",
    "    model_file = 'catboost'\n",
    "else:\n",
    "    dataset_path = '../data/data_processed/dataset_tree_models.pkl'\n",
    "    model_file = best_model_name.lower().replace(' ', '_')\n",
    "\n",
    "print(f\"\\nLoading dataset: {dataset_path}\")\n",
    "print(f\"Loading model: {model_file}_best.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97383ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "with open(dataset_path, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    X_train = data['X_train']\n",
    "    X_test = data['X_test']\n",
    "    y_train = data['y_train']\n",
    "    y_test = data['y_test']\n",
    "\n",
    "print(f\"\\nData loaded:\")\n",
    "print(f\"  Training set: {X_train.shape}\")\n",
    "print(f\"  Test set: {X_test.shape}\")\n",
    "print(f\"  Features: {X_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c72572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model\n",
    "model_path = f'../models/{model_file}_best.pkl'\n",
    "with open(model_path, 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "print(f\"Model loaded: {model_path}\")\n",
    "print(f\"Model type: {type(model).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536bf520",
   "metadata": {},
   "source": [
    "## 3. Initialize SHAP Explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fada3a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SHAP with JavaScript visualization\n",
    "shap.initjs()\n",
    "\n",
    "print(\"Creating SHAP explainer...\")\n",
    "print(\"This may take a few minutes...\\n\")\n",
    "\n",
    "# Use a sample of training data for efficiency (500 samples)\n",
    "X_train_sample = shap.sample(X_train, 500, random_state=42)\n",
    "\n",
    "# Create appropriate explainer based on model type\n",
    "model_type = type(model).__name__\n",
    "\n",
    "if 'XGB' in model_type or 'LGB' in model_type or 'CatBoost' in model_type:\n",
    "    # Tree-based models use TreeExplainer (fast and exact)\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    print(f\"Using TreeExplainer for {model_type}\")\n",
    "else:\n",
    "    # Linear models use LinearExplainer (fast and exact)\n",
    "    # Other models use KernelExplainer (slower but works for any model)\n",
    "    if hasattr(model, 'coef_'):\n",
    "        explainer = shap.LinearExplainer(model, X_train_sample)\n",
    "        print(f\"Using LinearExplainer for {model_type}\")\n",
    "    else:\n",
    "        explainer = shap.KernelExplainer(model.predict, X_train_sample)\n",
    "        print(f\"Using KernelExplainer for {model_type}\")\n",
    "\n",
    "print(\"✓ Explainer created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90fc5cb",
   "metadata": {},
   "source": [
    "## 4. Calculate SHAP Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afd4c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Calculating SHAP values for test set...\")\n",
    "print(\"This may take several minutes...\\n\")\n",
    "\n",
    "# Calculate SHAP values for test set (use subset for speed)\n",
    "X_test_sample = X_test.sample(min(1000, len(X_test)), random_state=42)\n",
    "shap_values = explainer.shap_values(X_test_sample)\n",
    "\n",
    "print(f\"✓ SHAP values calculated!\")\n",
    "print(f\"  Shape: {shap_values.shape if hasattr(shap_values, 'shape') else np.array(shap_values).shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d71ddb",
   "metadata": {},
   "source": [
    "## 5. Global Feature Importance\n",
    "\n",
    "**Summary Plot**: Shows which features are most important overall across all predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3053c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary plot (bar) - Feature importance\n",
    "plt.figure(figsize=(10, 8))\n",
    "shap.summary_plot(shap_values, X_test_sample, plot_type=\"bar\", show=False)\n",
    "plt.title('Feature Importance (Mean |SHAP Value|)', fontsize=14, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"- Features at the top have the strongest impact on RiskScore predictions\")\n",
    "print(\"- The bar length shows average absolute impact across all predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efecb6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary plot (beeswarm) - Feature importance with impact direction\n",
    "plt.figure(figsize=(10, 12))\n",
    "shap.summary_plot(shap_values, X_test_sample, show=False)\n",
    "plt.title('Feature Impact on RiskScore', fontsize=14, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"- Each dot is one prediction\")\n",
    "print(\"- Red = high feature value, Blue = low feature value\")\n",
    "print(\"- Right side (positive SHAP) = increases RiskScore (more risky)\")\n",
    "print(\"- Left side (negative SHAP) = decreases RiskScore (less risky)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcdc014",
   "metadata": {},
   "source": [
    "## 6. Individual Prediction Explanations\n",
    "\n",
    "**Waterfall plots**: Show how each feature contributes to a specific prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88a5fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions for the test sample\n",
    "y_test_sample = y_test.loc[X_test_sample.index]\n",
    "predictions = model.predict(X_test_sample)\n",
    "\n",
    "# Identify interesting cases\n",
    "low_risk_idx = predictions.argmin()  # Lowest predicted risk\n",
    "high_risk_idx = predictions.argmax()  # Highest predicted risk\n",
    "median_risk_idx = np.argsort(predictions)[len(predictions)//2]  # Median risk\n",
    "\n",
    "print(f\"Selected examples for detailed analysis:\")\n",
    "print(f\"  Low Risk:    Predicted={predictions[low_risk_idx]:.2f}, Actual={y_test_sample.iloc[low_risk_idx]:.2f}\")\n",
    "print(f\"  Median Risk: Predicted={predictions[median_risk_idx]:.2f}, Actual={y_test_sample.iloc[median_risk_idx]:.2f}\")\n",
    "print(f\"  High Risk:   Predicted={predictions[high_risk_idx]:.2f}, Actual={y_test_sample.iloc[high_risk_idx]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c473f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Waterfall plot for LOW RISK applicant\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXPLANATION FOR LOW RISK APPLICANT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "shap.waterfall_plot(shap.Explanation(values=shap_values[low_risk_idx], \n",
    "                                     base_values=explainer.expected_value if hasattr(explainer, 'expected_value') else predictions.mean(),\n",
    "                                     data=X_test_sample.iloc[low_risk_idx],\n",
    "                                     feature_names=X_test_sample.columns.tolist()), \n",
    "                    show=False)\n",
    "plt.title(f'Low Risk Prediction Explanation (RiskScore = {predictions[low_risk_idx]:.2f})', \n",
    "          fontsize=12, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"- E[f(x)] = Expected RiskScore (average across all applicants)\")\n",
    "print(\"- Each bar shows how a feature pushes the prediction up (red) or down (blue)\")\n",
    "print(\"- f(x) = Final predicted RiskScore for this specific applicant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfa372c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Waterfall plot for HIGH RISK applicant\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXPLANATION FOR HIGH RISK APPLICANT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "shap.waterfall_plot(shap.Explanation(values=shap_values[high_risk_idx], \n",
    "                                     base_values=explainer.expected_value if hasattr(explainer, 'expected_value') else predictions.mean(),\n",
    "                                     data=X_test_sample.iloc[high_risk_idx],\n",
    "                                     feature_names=X_test_sample.columns.tolist()), \n",
    "                    show=False)\n",
    "plt.title(f'High Risk Prediction Explanation (RiskScore = {predictions[high_risk_idx]:.2f})', \n",
    "          fontsize=12, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f86bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Waterfall plot for MEDIAN RISK applicant\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXPLANATION FOR MEDIAN RISK APPLICANT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "shap.waterfall_plot(shap.Explanation(values=shap_values[median_risk_idx], \n",
    "                                     base_values=explainer.expected_value if hasattr(explainer, 'expected_value') else predictions.mean(),\n",
    "                                     data=X_test_sample.iloc[median_risk_idx],\n",
    "                                     feature_names=X_test_sample.columns.tolist()), \n",
    "                    show=False)\n",
    "plt.title(f'Median Risk Prediction Explanation (RiskScore = {predictions[median_risk_idx]:.2f})', \n",
    "          fontsize=12, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ade4bd",
   "metadata": {},
   "source": [
    "## 7. Feature Dependence Plots\n",
    "\n",
    "Shows how individual features affect RiskScore predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fafedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top 6 most important features\n",
    "mean_abs_shap = np.abs(shap_values).mean(axis=0)\n",
    "top_features_idx = np.argsort(mean_abs_shap)[-6:][::-1]\n",
    "top_features = X_test_sample.columns[top_features_idx].tolist()\n",
    "\n",
    "print(\"Top 6 Most Important Features:\")\n",
    "for i, feat in enumerate(top_features, 1):\n",
    "    print(f\"{i}. {feat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078aa72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dependence plots for top features\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, feature in enumerate(top_features):\n",
    "    plt.sca(axes[idx])\n",
    "    shap.dependence_plot(feature, shap_values, X_test_sample, ax=axes[idx], show=False)\n",
    "    axes[idx].set_title(f'{feature}', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.suptitle('Feature Dependence Plots - Top 6 Features', fontsize=14, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"- X-axis: Feature value\")\n",
    "print(\"- Y-axis: SHAP value (impact on RiskScore)\")\n",
    "print(\"- Color: Interaction with another feature\")\n",
    "print(\"- Shows how changing a feature value affects the predicted risk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2d2f39",
   "metadata": {},
   "source": [
    "## 8. Force Plots - Interactive Explanation\n",
    "\n",
    "Interactive visualization showing how features push predictions from the base value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48e89bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force plot for a single prediction\n",
    "print(\"Force plot for HIGH RISK applicant:\")\n",
    "print(\"(Interactive visualization - red pushes risk higher, blue pushes lower)\\n\")\n",
    "\n",
    "shap.force_plot(\n",
    "    explainer.expected_value if hasattr(explainer, 'expected_value') else predictions.mean(),\n",
    "    shap_values[high_risk_idx],\n",
    "    X_test_sample.iloc[high_risk_idx],\n",
    "    matplotlib=True,\n",
    "    show=False\n",
    ")\n",
    "plt.title(f'Force Plot - High Risk Applicant (RiskScore = {predictions[high_risk_idx]:.2f})', \n",
    "          fontsize=12, fontweight='bold', pad=10)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcca24e",
   "metadata": {},
   "source": [
    "## 9. Business Insights from SHAP Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36282af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate feature contribution statistics\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': X_test_sample.columns,\n",
    "    'Mean_Abs_SHAP': np.abs(shap_values).mean(axis=0),\n",
    "    'Mean_SHAP': shap_values.mean(axis=0),\n",
    "    'Std_SHAP': shap_values.std(axis=0)\n",
    "}).sort_values('Mean_Abs_SHAP', ascending=False)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"KEY INSIGHTS FOR LOAN DECISION MAKERS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1. TOP 10 MOST INFLUENTIAL FEATURES:\")\n",
    "print(\"=\"*80)\n",
    "for idx, row in feature_importance_df.head(10).iterrows():\n",
    "    direction = \"↑ Increases\" if row['Mean_SHAP'] > 0 else \"↓ Decreases\"\n",
    "    print(f\"   {row['Feature']:30s} | Impact: {row['Mean_Abs_SHAP']:.4f} | {direction} risk\")\n",
    "\n",
    "print(\"\\n2. RISK DRIVERS (Features that typically INCREASE RiskScore):\")\n",
    "print(\"=\"*80)\n",
    "risk_drivers = feature_importance_df[feature_importance_df['Mean_SHAP'] > 0].head(5)\n",
    "for idx, row in risk_drivers.iterrows():\n",
    "    print(f\"   ⚠️  {row['Feature']:30s} | Avg. Impact: +{row['Mean_SHAP']:.4f}\")\n",
    "\n",
    "print(\"\\n3. RISK REDUCERS (Features that typically DECREASE RiskScore):\")\n",
    "print(\"=\"*80)\n",
    "risk_reducers = feature_importance_df[feature_importance_df['Mean_SHAP'] < 0].head(5)\n",
    "for idx, row in risk_reducers.iterrows():\n",
    "    print(f\"   ✓  {row['Feature']:30s} | Avg. Impact: {row['Mean_SHAP']:.4f}\")\n",
    "\n",
    "print(\"\\n4. RECOMMENDATIONS FOR LOAN OFFICERS:\")\n",
    "print(\"=\"*80)\n",
    "print(\"   • Pay special attention to the top 3-5 features when reviewing applications\")\n",
    "print(\"   • For borderline cases, examine risk driver features in detail\")\n",
    "print(\"   • Request additional documentation for high-impact negative features\")\n",
    "print(\"   • Use SHAP explanations to justify decisions to customers\")\n",
    "print(\"   • Monitor if model focuses on fair, non-discriminatory features\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1e9b5b",
   "metadata": {},
   "source": [
    "## 10. Export SHAP Values for Further Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0bf6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save feature importance ranking\n",
    "feature_importance_df.to_csv('../models/shap_feature_importance.csv', index=False)\n",
    "print(\"✓ Feature importance saved to: ../models/shap_feature_importance.csv\")\n",
    "\n",
    "# Save SHAP values for test set\n",
    "shap_df = pd.DataFrame(shap_values, columns=X_test_sample.columns, index=X_test_sample.index)\n",
    "shap_df['Predicted_RiskScore'] = predictions\n",
    "shap_df['Actual_RiskScore'] = y_test_sample.values\n",
    "shap_df.to_csv('../models/shap_values_test_set.csv')\n",
    "print(\"✓ SHAP values saved to: ../models/shap_values_test_set.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SHAP ANALYSIS COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nYou now have:\")\n",
    "print(\"  1. Global feature importance rankings\")\n",
    "print(\"  2. Individual prediction explanations\")\n",
    "print(\"  3. Feature dependence patterns\")\n",
    "print(\"  4. Business insights for decision makers\")\n",
    "print(\"  5. Exported data for further analysis\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
