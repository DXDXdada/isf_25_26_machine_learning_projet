{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd1cc979",
   "metadata": {},
   "source": [
    "# Notebook 4 : Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e96c2b5",
   "metadata": {},
   "source": [
    "## Configuration de l'environnement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2be468de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import os\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Sklearn models\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Boosting libraries\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a4caed",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d429ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed: 42\n",
      "Cross-validation: 5-Fold\n"
     ]
    }
   ],
   "source": [
    "# Set random seed for reproducibility\n",
    "R_seed = 42\n",
    "np.random.seed(R_seed)\n",
    "\n",
    "# K-Fold Cross-Validation setup\n",
    "N_FOLDS = 5\n",
    "kfold = KFold(n_splits=N_FOLDS, shuffle=True, random_state=R_seed)\n",
    "\n",
    "print(f\"Random seed: {R_seed}\")\n",
    "print(f\"Cross-validation: {N_FOLDS}-Fold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0537f792",
   "metadata": {},
   "source": [
    "## Load Preprocessed Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea99b8c4",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1 (Linear Models) loaded:\n",
      "  Train: (16000, 57), Test: (4000, 57)\n",
      "\n",
      "Dataset 2 (Tree Models) loaded:\n",
      "  Train: (16000, 75), Test: (4000, 75)\n",
      "\n",
      "Dataset 3 (CatBoost) loaded:\n",
      "  Train: (16000, 67), Test: (4000, 67)\n",
      "  Categorical features: 11\n"
     ]
    }
   ],
   "source": [
    "# Load Dataset 1: Linear Models\n",
    "with open('../data/data_processed/dataset_linear_models.pkl', 'rb') as f:\n",
    "    data_linear = pickle.load(f)\n",
    "    X_train_linear = data_linear['X_train']\n",
    "    X_test_linear = data_linear['X_test']\n",
    "    y_train_linear = data_linear['y_train']\n",
    "    y_test_linear = data_linear['y_test']\n",
    "\n",
    "print(\"Dataset 1 (Linear Models) loaded:\")\n",
    "print(f\"  Train: {X_train_linear.shape}, Test: {X_test_linear.shape}\")\n",
    "\n",
    "# Load Dataset 2: Tree-based Models\n",
    "with open('../data/data_processed/dataset_tree_models.pkl', 'rb') as f:\n",
    "    data_tree = pickle.load(f)\n",
    "    X_train_tree = data_tree['X_train']\n",
    "    X_test_tree = data_tree['X_test']\n",
    "    y_train_tree = data_tree['y_train']\n",
    "    y_test_tree = data_tree['y_test']\n",
    "\n",
    "print(\"\\nDataset 2 (Tree Models) loaded:\")\n",
    "print(f\"  Train: {X_train_tree.shape}, Test: {X_test_tree.shape}\")\n",
    "\n",
    "# Load Dataset 3: CatBoost\n",
    "with open('../data/data_processed/dataset_catboost.pkl', 'rb') as f:\n",
    "    data_catboost = pickle.load(f)\n",
    "    X_train_catboost = data_catboost['X_train']\n",
    "    X_test_catboost = data_catboost['X_test']\n",
    "    y_train_catboost = data_catboost['y_train']\n",
    "    y_test_catboost = data_catboost['y_test']\n",
    "    cat_features_idx = data_catboost['cat_features_idx']\n",
    "\n",
    "print(\"\\nDataset 3 (CatBoost) loaded:\")\n",
    "print(f\"  Train: {X_train_catboost.shape}, Test: {X_test_catboost.shape}\")\n",
    "print(f\"  Categorical features: {len(cat_features_idx)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ecb944",
   "metadata": {},
   "source": [
    "## Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a00f827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation function defined\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, X_train, y_train, X_test, y_test, model_name):\n",
    "    \"\"\"\n",
    "    Evaluate a trained model on train and test sets.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : trained model\n",
    "    X_train, y_train : training data\n",
    "    X_test, y_test : test data\n",
    "    model_name : str, name of the model\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : metrics for train and test\n",
    "    \"\"\"\n",
    "    \n",
    "    # Predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = {\n",
    "        'Model': model_name,\n",
    "        'Train_RMSE': np.sqrt(mean_squared_error(y_train, y_train_pred)),\n",
    "        'Train_MAE': mean_absolute_error(y_train, y_train_pred),\n",
    "        'Train_R2': r2_score(y_train, y_train_pred),\n",
    "        'Test_RMSE': np.sqrt(mean_squared_error(y_test, y_test_pred)),\n",
    "        'Test_MAE': mean_absolute_error(y_test, y_test_pred),\n",
    "        'Test_R2': r2_score(y_test, y_test_pred)\n",
    "    }\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"{model_name} - Performance Metrics\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Training Set:\")\n",
    "    print(f\"  RMSE: {metrics['Train_RMSE']:.4f}\")\n",
    "    print(f\"  MAE:  {metrics['Train_MAE']:.4f}\")\n",
    "    print(f\"  R¬≤:   {metrics['Train_R2']:.4f}\")\n",
    "    print(f\"\\nTest Set:\")\n",
    "    print(f\"  RMSE: {metrics['Test_RMSE']:.4f}\")\n",
    "    print(f\"  MAE:  {metrics['Test_MAE']:.4f}\")\n",
    "    print(f\"  R¬≤:   {metrics['Test_R2']:.4f}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Initialize results storage\n",
    "all_results = []\n",
    "\n",
    "print(\"Evaluation function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec487e50",
   "metadata": {},
   "source": [
    "---\n",
    "# Model 1: Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a21eb73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Ridge Regression...\n",
      "Fitting 5 folds for each of 77 candidates, totalling 385 fits\n",
      "\n",
      "Best parameters: {'alpha': 0.01, 'solver': 'auto'}\n",
      "Best CV RMSE: 3.4540\n",
      "\n",
      "================================================================================\n",
      "Ridge Regression - Performance Metrics\n",
      "================================================================================\n",
      "Training Set:\n",
      "  RMSE: 3.4332\n",
      "  MAE:  2.6907\n",
      "  R¬≤:   0.8038\n",
      "\n",
      "Test Set:\n",
      "  RMSE: 3.6508\n",
      "  MAE:  2.8106\n",
      "  R¬≤:   0.7853\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Ridge Regression...\")\n",
    "\n",
    "# Extensive hyperparameter grid\n",
    "ridge_params = {\n",
    "    'alpha': [0.001, 0.01, 0.1, 0.5, 1.0, 5.0, 10.0, 50.0, 100.0, 500.0, 1000.0],\n",
    "    'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']\n",
    "}\n",
    "\n",
    "ridge = Ridge(random_state=R_seed, max_iter=10000)\n",
    "ridge_grid = GridSearchCV(\n",
    "    ridge, \n",
    "    ridge_params, \n",
    "    cv=kfold, \n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "ridge_grid.fit(X_train_linear, y_train_linear)\n",
    "\n",
    "print(f\"\\nBest parameters: {ridge_grid.best_params_}\")\n",
    "print(f\"Best CV RMSE: {-ridge_grid.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate\n",
    "ridge_best = ridge_grid.best_estimator_\n",
    "ridge_metrics = evaluate_model(\n",
    "    ridge_best, \n",
    "    X_train_linear, y_train_linear, \n",
    "    X_test_linear, y_test_linear,\n",
    "    'Ridge Regression'\n",
    ")\n",
    "all_results.append(ridge_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d5c648",
   "metadata": {},
   "source": [
    "---\n",
    "# Model 2: Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e88a9db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Lasso Regression...\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "\n",
      "Best parameters: {'alpha': 0.001, 'selection': 'cyclic'}\n",
      "Best CV RMSE: 3.4541\n",
      "\n",
      "================================================================================\n",
      "Lasso Regression - Performance Metrics\n",
      "================================================================================\n",
      "Training Set:\n",
      "  RMSE: 3.4337\n",
      "  MAE:  2.6903\n",
      "  R¬≤:   0.8037\n",
      "\n",
      "Test Set:\n",
      "  RMSE: 3.6487\n",
      "  MAE:  2.8083\n",
      "  R¬≤:   0.7856\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Lasso Regression...\")\n",
    "\n",
    "# Extensive hyperparameter grid\n",
    "lasso_params = {\n",
    "    'alpha': [0.001, 0.01, 0.1, 0.5, 1.0, 5.0, 10.0, 50.0, 100.0],\n",
    "    'selection': ['cyclic', 'random']\n",
    "}\n",
    "\n",
    "lasso = Lasso(random_state=R_seed, max_iter=10000)\n",
    "lasso_grid = GridSearchCV(\n",
    "    lasso, \n",
    "    lasso_params, \n",
    "    cv=kfold, \n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "lasso_grid.fit(X_train_linear, y_train_linear)\n",
    "\n",
    "print(f\"\\nBest parameters: {lasso_grid.best_params_}\")\n",
    "print(f\"Best CV RMSE: {-lasso_grid.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate\n",
    "lasso_best = lasso_grid.best_estimator_\n",
    "lasso_metrics = evaluate_model(\n",
    "    lasso_best, \n",
    "    X_train_linear, y_train_linear, \n",
    "    X_test_linear, y_test_linear,\n",
    "    'Lasso Regression'\n",
    ")\n",
    "all_results.append(lasso_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee760b3",
   "metadata": {},
   "source": [
    "---\n",
    "# Model 3: ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f39d8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ElasticNet...\n",
      "Fitting 5 folds for each of 112 candidates, totalling 560 fits\n",
      "\n",
      "Best parameters: {'alpha': 0.001, 'l1_ratio': 0.99, 'selection': 'cyclic'}\n",
      "Best CV RMSE: 3.4542\n",
      "\n",
      "================================================================================\n",
      "ElasticNet - Performance Metrics\n",
      "================================================================================\n",
      "Training Set:\n",
      "  RMSE: 3.4338\n",
      "  MAE:  2.6903\n",
      "  R¬≤:   0.8037\n",
      "\n",
      "Test Set:\n",
      "  RMSE: 3.6486\n",
      "  MAE:  2.8082\n",
      "  R¬≤:   0.7856\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"Training ElasticNet...\")\n",
    "\n",
    "# Extensive hyperparameter grid\n",
    "elasticnet_params = {\n",
    "    'alpha': [0.001, 0.01, 0.1, 0.5, 1.0, 5.0, 10.0, 50.0],\n",
    "    'l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9, 0.95, 0.99],\n",
    "    'selection': ['cyclic', 'random']\n",
    "}\n",
    "\n",
    "elasticnet = ElasticNet(random_state=R_seed, max_iter=10000)\n",
    "elasticnet_grid = GridSearchCV(\n",
    "    elasticnet, \n",
    "    elasticnet_params, \n",
    "    cv=kfold, \n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "elasticnet_grid.fit(X_train_linear, y_train_linear)\n",
    "\n",
    "print(f\"\\nBest parameters: {elasticnet_grid.best_params_}\")\n",
    "print(f\"Best CV RMSE: {-elasticnet_grid.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate\n",
    "elasticnet_best = elasticnet_grid.best_estimator_\n",
    "elasticnet_metrics = evaluate_model(\n",
    "    elasticnet_best, \n",
    "    X_train_linear, y_train_linear, \n",
    "    X_test_linear, y_test_linear,\n",
    "    'ElasticNet'\n",
    ")\n",
    "all_results.append(elasticnet_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a62d9e",
   "metadata": {},
   "source": [
    "---\n",
    "# Model 4: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed31997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest Regressor...\n",
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n",
      "\n",
      "Best parameters: {'bootstrap': False, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "Best CV RMSE: 3.2242\n",
      "\n",
      "================================================================================\n",
      "Random Forest - Performance Metrics\n",
      "================================================================================\n",
      "Training Set:\n",
      "  RMSE: 0.0000\n",
      "  MAE:  0.0000\n",
      "  R¬≤:   1.0000\n",
      "\n",
      "Test Set:\n",
      "  RMSE: 3.2527\n",
      "  MAE:  2.2860\n",
      "  R¬≤:   0.8296\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Random Forest Regressor...\")\n",
    "# Optimized hyperparameter grid (reduced for efficiency)\n",
    "rf_params = {\n",
    "    'n_estimators': [100, 300, 500],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=R_seed, n_jobs=-1)\n",
    "rf_grid = GridSearchCV(\n",
    "    rf, \n",
    "    rf_params, \n",
    "    cv=kfold, \n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "rf_grid.fit(X_train_tree, y_train_tree)\n",
    "\n",
    "print(f\"\\nBest parameters: {rf_grid.best_params_}\")\n",
    "print(f\"Best CV RMSE: {-rf_grid.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate\n",
    "rf_best = rf_grid.best_estimator_\n",
    "rf_metrics = evaluate_model(\n",
    "    rf_best, \n",
    "    X_train_tree, y_train_tree, \n",
    "    X_test_tree, y_test_tree,\n",
    "    'Random Forest'\n",
    ")\n",
    "all_results.append(rf_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450c9a25",
   "metadata": {},
   "source": [
    "---\n",
    "# Model 5: XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b89a1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost Regressor...\n",
      "Fitting 5 folds for each of 2916 candidates, totalling 14580 fits\n",
      "\n",
      "Best parameters: {'colsample_bytree': 0.8, 'gamma': 0.1, 'learning_rate': 0.05, 'max_depth': 7, 'min_child_weight': 5, 'n_estimators': 500, 'subsample': 0.7}\n",
      "Best CV RMSE: 2.2462\n",
      "\n",
      "================================================================================\n",
      "XGBoost - Performance Metrics\n",
      "================================================================================\n",
      "Training Set:\n",
      "  RMSE: 0.7214\n",
      "  MAE:  0.4704\n",
      "  R¬≤:   0.9913\n",
      "\n",
      "Test Set:\n",
      "  RMSE: 2.2524\n",
      "  MAE:  1.4138\n",
      "  R¬≤:   0.9183\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"Training XGBoost Regressor...\")\n",
    "\n",
    "# Optimized hyperparameter grid (reduced for efficiency)\n",
    "xgb_params = {\n",
    "    'n_estimators': [100, 300, 500],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'subsample': [0.7, 0.8, 0.9],\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'gamma': [0, 0.1, 0.3]\n",
    "}\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    random_state=R_seed,\n",
    "    n_jobs=-1,\n",
    "    tree_method='hist'\n",
    ")\n",
    "\n",
    "xgb_grid = GridSearchCV(\n",
    "    xgb_model, \n",
    "    xgb_params, \n",
    "    cv=kfold, \n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "xgb_grid.fit(X_train_tree, y_train_tree)\n",
    "\n",
    "print(f\"\\nBest parameters: {xgb_grid.best_params_}\")\n",
    "print(f\"Best CV RMSE: {-xgb_grid.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate\n",
    "xgb_best = xgb_grid.best_estimator_\n",
    "xgb_metrics = evaluate_model(\n",
    "    xgb_best, \n",
    "    X_train_tree, y_train_tree, \n",
    "    X_test_tree, y_test_tree,\n",
    "    'XGBoost'\n",
    ")\n",
    "all_results.append(xgb_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0494a4ed",
   "metadata": {},
   "source": [
    "---\n",
    "# Model 6: LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7924ba8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LightGBM Regressor...\n",
      "Fitting 5 folds for each of 17496 candidates, totalling 87480 fits\n"
     ]
    }
   ],
   "source": [
    "print(\"Training LightGBM Regressor...\")\n",
    "\n",
    "# Optimized hyperparameter grid (reduced for efficiency)\n",
    "lgb_params = {\n",
    "    'n_estimators': [100, 300, 500],\n",
    "    'max_depth': [5, 7, 10, -1],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'num_leaves': [31, 63, 127],\n",
    "    'subsample': [0.7, 0.8, 0.9],\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9],\n",
    "    'min_child_samples': [10, 20],\n",
    "    'reg_alpha': [0, 0.1, 0.5],\n",
    "    'reg_lambda': [0, 0.1, 0.5]\n",
    "}\n",
    "\n",
    "lgb_model = lgb.LGBMRegressor(\n",
    "    random_state=R_seed,\n",
    "    n_jobs=-1,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "lgb_grid = GridSearchCV(\n",
    "    lgb_model, \n",
    "    lgb_params, \n",
    "    cv=kfold, \n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "lgb_grid.fit(X_train_tree, y_train_tree)\n",
    "\n",
    "print(f\"\\nBest parameters: {lgb_grid.best_params_}\")\n",
    "print(f\"Best CV RMSE: {-lgb_grid.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate\n",
    "lgb_best = lgb_grid.best_estimator_\n",
    "lgb_metrics = evaluate_model(\n",
    "    lgb_best, \n",
    "    X_train_tree, y_train_tree, \n",
    "    X_test_tree, y_test_tree,\n",
    "    'LightGBM'\n",
    ")\n",
    "all_results.append(lgb_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9bc98e",
   "metadata": {},
   "source": [
    "---\n",
    "# Model 7: CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43b8f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training CatBoost Regressor...\")\n",
    "\n",
    "# Optimized hyperparameter grid (reduced for efficiency)\n",
    "catboost_params = {\n",
    "    'iterations': [100, 300, 500],\n",
    "    'depth': [4, 6, 8, 10],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'l2_leaf_reg': [1, 3, 5],\n",
    "    'border_count': [64, 128],\n",
    "    'bagging_temperature': [0, 0.5, 1.0],\n",
    "    'random_strength': [1, 2]\n",
    "}\n",
    "\n",
    "catboost_model = CatBoostRegressor(\n",
    "    random_state=R_seed,\n",
    "    verbose=0,\n",
    "    thread_count=-1,\n",
    "    cat_features=cat_features_idx\n",
    ")\n",
    "\n",
    "catboost_grid = GridSearchCV(\n",
    "    catboost_model, \n",
    "    catboost_params, \n",
    "    cv=kfold, \n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=1,  # CatBoost handles parallelization internally\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "catboost_grid.fit(X_train_catboost, y_train_catboost)\n",
    "\n",
    "print(f\"\\nBest parameters: {catboost_grid.best_params_}\")\n",
    "print(f\"Best CV RMSE: {-catboost_grid.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate\n",
    "catboost_best = catboost_grid.best_estimator_\n",
    "catboost_metrics = evaluate_model(\n",
    "    catboost_best, \n",
    "    X_train_catboost, y_train_catboost, \n",
    "    X_test_catboost, y_test_catboost,\n",
    "    'CatBoost'\n",
    ")\n",
    "all_results.append(catboost_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61d3caa",
   "metadata": {},
   "source": [
    "---\n",
    "## Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf0f8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison dataframe\n",
    "results_df = pd.DataFrame(all_results)\n",
    "results_df = results_df.sort_values('Test RMSE')\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"COMPREHENSIVE MODEL COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nAll Models Ranked by Test RMSE:\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"BEST MODEL:\")\n",
    "print(\"=\" * 80)\n",
    "best_model = results_df.iloc[0]\n",
    "print(f\"\\nüèÜ {best_model['Model']}\")\n",
    "print(f\"   Test RMSE: {best_model['Test RMSE']:.4f}\")\n",
    "print(f\"   Test MAE:  {best_model['Test MAE']:.4f}\")\n",
    "print(f\"   Test R¬≤:   {best_model['Test R2']:.4f}\")\n",
    "print(f\"   Train RMSE: {best_model['Train RMSE']:.4f}\")\n",
    "print(f\"   Overfitting Gap: {best_model['Train RMSE'] - best_model['Test RMSE']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15af26de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. Test RMSE Comparison\n",
    "axes[0, 0].barh(results_df['Model'], results_df['Test RMSE'], color='steelblue')\n",
    "axes[0, 0].set_xlabel('RMSE')\n",
    "axes[0, 0].set_title('Test RMSE by Model (Lower is Better)')\n",
    "axes[0, 0].invert_yaxis()\n",
    "\n",
    "# 2. Test MAE Comparison\n",
    "axes[0, 1].barh(results_df['Model'], results_df['Test MAE'], color='coral')\n",
    "axes[0, 1].set_xlabel('MAE')\n",
    "axes[0, 1].set_title('Test MAE by Model (Lower is Better)')\n",
    "axes[0, 1].invert_yaxis()\n",
    "\n",
    "# 3. Test R¬≤ Comparison\n",
    "axes[1, 0].barh(results_df['Model'], results_df['Test R2'], color='seagreen')\n",
    "axes[1, 0].set_xlabel('R¬≤')\n",
    "axes[1, 0].set_title('Test R¬≤ by Model (Higher is Better)')\n",
    "axes[1, 0].invert_yaxis()\n",
    "\n",
    "# 4. Train vs Test RMSE (Overfitting Check)\n",
    "x = range(len(results_df))\n",
    "width = 0.35\n",
    "axes[1, 1].bar([i - width/2 for i in x], results_df['Train RMSE'], width, label='Train', color='lightblue')\n",
    "axes[1, 1].bar([i + width/2 for i in x], results_df['Test RMSE'], width, label='Test', color='darkblue')\n",
    "axes[1, 1].set_xlabel('Model')\n",
    "axes[1, 1].set_ylabel('RMSE')\n",
    "axes[1, 1].set_title('Train vs Test RMSE (Overfitting Check)')\n",
    "axes[1, 1].set_xticks(x)\n",
    "axes[1, 1].set_xticklabels(results_df['Model'], rotation=45, ha='right')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be42628",
   "metadata": {},
   "source": [
    "---\n",
    "## Save Best Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d67338",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create models directory if it doesn't exist\n",
    "models_dir = '../models'\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "# Save all trained models\n",
    "models_to_save = {\n",
    "    'ridge': ridge_grid,\n",
    "    'lasso': lasso_grid,\n",
    "    'elasticnet': elasticnet_grid,\n",
    "    'random_forest': rf_grid,\n",
    "    'xgboost': xgb_grid,\n",
    "    'lightgbm': lgbm_grid,\n",
    "    'catboost': catboost_grid\n",
    "}\n",
    "\n",
    "for model_name, model in models_to_save.items():\n",
    "    filepath = os.path.join(models_dir, f'{model_name}_best.pkl')\n",
    "    with open(filepath, 'wb') as f:\n",
    "        pickle.dump(model.best_estimator_, f)\n",
    "    print(f\"‚úì Saved {model_name} to {filepath}\")\n",
    "\n",
    "# Save the complete GridSearchCV objects (includes all hyperparameter search history)\n",
    "for model_name, model in models_to_save.items():\n",
    "    filepath = os.path.join(models_dir, f'{model_name}_gridsearch.pkl')\n",
    "    with open(filepath, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "    print(f\"‚úì Saved {model_name} GridSearch to {filepath}\")\n",
    "\n",
    "# Save the comparison results\n",
    "results_filepath = os.path.join(models_dir, 'model_comparison_results.csv')\n",
    "results_df.to_csv(results_filepath, index=False)\n",
    "print(f\"\\n‚úì Saved comparison results to {results_filepath}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"All models saved successfully!\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
