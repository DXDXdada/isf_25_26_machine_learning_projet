{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd1cc979",
   "metadata": {},
   "source": [
    "# Notebook 4 : Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e96c2b5",
   "metadata": {},
   "source": [
    "## Configuration de l'environnement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2be468de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import os\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Sklearn models\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Boosting libraries\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a4caed",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d429ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed: 42\n",
      "Cross-validation: 5-Fold\n"
     ]
    }
   ],
   "source": [
    "# Set random seed for reproducibility\n",
    "R_seed = 42\n",
    "np.random.seed(R_seed)\n",
    "\n",
    "# K-Fold Cross-Validation setup\n",
    "N_FOLDS = 5\n",
    "kfold = KFold(n_splits=N_FOLDS, shuffle=True, random_state=R_seed)\n",
    "\n",
    "print(f\"Random seed: {R_seed}\")\n",
    "print(f\"Cross-validation: {N_FOLDS}-Fold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0537f792",
   "metadata": {},
   "source": [
    "## Load Preprocessed Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea99b8c4",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1 (Linear Models) loaded:\n",
      "  Train: (16000, 57), Test: (4000, 57)\n",
      "\n",
      "Dataset 2 (Tree Models) loaded:\n",
      "  Train: (16000, 75), Test: (4000, 75)\n",
      "\n",
      "Dataset 3 (CatBoost) loaded:\n",
      "  Train: (16000, 67), Test: (4000, 67)\n",
      "  Categorical features: 11\n"
     ]
    }
   ],
   "source": [
    "# Load Dataset 1: Linear Models\n",
    "with open('../data/data_processed/dataset_linear_models.pkl', 'rb') as f:\n",
    "    data_linear = pickle.load(f)\n",
    "    X_train_linear = data_linear['X_train']\n",
    "    X_test_linear = data_linear['X_test']\n",
    "    y_train_linear = data_linear['y_train']\n",
    "    y_test_linear = data_linear['y_test']\n",
    "\n",
    "print(\"Dataset 1 (Linear Models) loaded:\")\n",
    "print(f\"  Train: {X_train_linear.shape}, Test: {X_test_linear.shape}\")\n",
    "\n",
    "# Load Dataset 2: Tree-based Models\n",
    "with open('../data/data_processed/dataset_tree_models.pkl', 'rb') as f:\n",
    "    data_tree = pickle.load(f)\n",
    "    X_train_tree = data_tree['X_train']\n",
    "    X_test_tree = data_tree['X_test']\n",
    "    y_train_tree = data_tree['y_train']\n",
    "    y_test_tree = data_tree['y_test']\n",
    "\n",
    "print(\"\\nDataset 2 (Tree Models) loaded:\")\n",
    "print(f\"  Train: {X_train_tree.shape}, Test: {X_test_tree.shape}\")\n",
    "\n",
    "# Load Dataset 3: CatBoost\n",
    "with open('../data/data_processed/dataset_catboost.pkl', 'rb') as f:\n",
    "    data_catboost = pickle.load(f)\n",
    "    X_train_catboost = data_catboost['X_train']\n",
    "    X_test_catboost = data_catboost['X_test']\n",
    "    y_train_catboost = data_catboost['y_train']\n",
    "    y_test_catboost = data_catboost['y_test']\n",
    "    cat_features_idx = data_catboost['cat_features_idx']\n",
    "\n",
    "print(\"\\nDataset 3 (CatBoost) loaded:\")\n",
    "print(f\"  Train: {X_train_catboost.shape}, Test: {X_test_catboost.shape}\")\n",
    "print(f\"  Categorical features: {len(cat_features_idx)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ecb944",
   "metadata": {},
   "source": [
    "## Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a00f827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation function defined\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, X_train, y_train, X_test, y_test, model_name):\n",
    "    \"\"\"\n",
    "    Evaluate a trained model on train and test sets.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : trained model\n",
    "    X_train, y_train : training data\n",
    "    X_test, y_test : test data\n",
    "    model_name : str, name of the model\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : metrics for train and test\n",
    "    \"\"\"\n",
    "    \n",
    "    # Predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = {\n",
    "        'Model': model_name,\n",
    "        'Train_RMSE': np.sqrt(mean_squared_error(y_train, y_train_pred)),\n",
    "        'Train_MAE': mean_absolute_error(y_train, y_train_pred),\n",
    "        'Train_R2': r2_score(y_train, y_train_pred),\n",
    "        'Test_RMSE': np.sqrt(mean_squared_error(y_test, y_test_pred)),\n",
    "        'Test_MAE': mean_absolute_error(y_test, y_test_pred),\n",
    "        'Test_R2': r2_score(y_test, y_test_pred)\n",
    "    }\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"{model_name} - Performance Metrics\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Training Set:\")\n",
    "    print(f\"  RMSE: {metrics['Train_RMSE']:.4f}\")\n",
    "    print(f\"  MAE:  {metrics['Train_MAE']:.4f}\")\n",
    "    print(f\"  R¬≤:   {metrics['Train_R2']:.4f}\")\n",
    "    print(f\"\\nTest Set:\")\n",
    "    print(f\"  RMSE: {metrics['Test_RMSE']:.4f}\")\n",
    "    print(f\"  MAE:  {metrics['Test_MAE']:.4f}\")\n",
    "    print(f\"  R¬≤:   {metrics['Test_R2']:.4f}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Initialize results storage\n",
    "all_results = []\n",
    "\n",
    "print(\"Evaluation function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec487e50",
   "metadata": {},
   "source": [
    "---\n",
    "# Model 1: Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a21eb73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Ridge Regression...\n",
      "Fitting 5 folds for each of 77 candidates, totalling 385 fits\n",
      "\n",
      "Best parameters: {'alpha': 0.01, 'solver': 'auto'}\n",
      "Best CV RMSE: 3.4540\n",
      "\n",
      "================================================================================\n",
      "Ridge Regression - Performance Metrics\n",
      "================================================================================\n",
      "Training Set:\n",
      "  RMSE: 3.4332\n",
      "  MAE:  2.6907\n",
      "  R¬≤:   0.8038\n",
      "\n",
      "Test Set:\n",
      "  RMSE: 3.6508\n",
      "  MAE:  2.8106\n",
      "  R¬≤:   0.7853\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Ridge Regression...\")\n",
    "\n",
    "# Extensive hyperparameter grid\n",
    "ridge_params = {\n",
    "    'alpha': [0.001, 0.01, 0.1, 0.5, 1.0, 5.0, 10.0, 50.0, 100.0, 500.0, 1000.0],\n",
    "    'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']\n",
    "}\n",
    "\n",
    "ridge = Ridge(random_state=R_seed, max_iter=10000)\n",
    "ridge_grid = GridSearchCV(\n",
    "    ridge, \n",
    "    ridge_params, \n",
    "    cv=kfold, \n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "ridge_grid.fit(X_train_linear, y_train_linear)\n",
    "\n",
    "print(f\"\\nBest parameters: {ridge_grid.best_params_}\")\n",
    "print(f\"Best CV RMSE: {-ridge_grid.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate\n",
    "ridge_best = ridge_grid.best_estimator_\n",
    "ridge_metrics = evaluate_model(\n",
    "    ridge_best, \n",
    "    X_train_linear, y_train_linear, \n",
    "    X_test_linear, y_test_linear,\n",
    "    'Ridge Regression'\n",
    ")\n",
    "all_results.append(ridge_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d5c648",
   "metadata": {},
   "source": [
    "---\n",
    "# Model 2: Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e88a9db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Lasso Regression...\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "\n",
      "Best parameters: {'alpha': 0.001, 'selection': 'cyclic'}\n",
      "Best CV RMSE: 3.4541\n",
      "\n",
      "================================================================================\n",
      "Lasso Regression - Performance Metrics\n",
      "================================================================================\n",
      "Training Set:\n",
      "  RMSE: 3.4337\n",
      "  MAE:  2.6903\n",
      "  R¬≤:   0.8037\n",
      "\n",
      "Test Set:\n",
      "  RMSE: 3.6487\n",
      "  MAE:  2.8083\n",
      "  R¬≤:   0.7856\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Lasso Regression...\")\n",
    "\n",
    "# Extensive hyperparameter grid\n",
    "lasso_params = {\n",
    "    'alpha': [0.001, 0.01, 0.1, 0.5, 1.0, 5.0, 10.0, 50.0, 100.0],\n",
    "    'selection': ['cyclic', 'random']\n",
    "}\n",
    "\n",
    "lasso = Lasso(random_state=R_seed, max_iter=10000)\n",
    "lasso_grid = GridSearchCV(\n",
    "    lasso, \n",
    "    lasso_params, \n",
    "    cv=kfold, \n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "lasso_grid.fit(X_train_linear, y_train_linear)\n",
    "\n",
    "print(f\"\\nBest parameters: {lasso_grid.best_params_}\")\n",
    "print(f\"Best CV RMSE: {-lasso_grid.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate\n",
    "lasso_best = lasso_grid.best_estimator_\n",
    "lasso_metrics = evaluate_model(\n",
    "    lasso_best, \n",
    "    X_train_linear, y_train_linear, \n",
    "    X_test_linear, y_test_linear,\n",
    "    'Lasso Regression'\n",
    ")\n",
    "all_results.append(lasso_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee760b3",
   "metadata": {},
   "source": [
    "---\n",
    "# Model 3: ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f39d8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ElasticNet...\n",
      "Fitting 5 folds for each of 112 candidates, totalling 560 fits\n",
      "\n",
      "Best parameters: {'alpha': 0.001, 'l1_ratio': 0.99, 'selection': 'cyclic'}\n",
      "Best CV RMSE: 3.4542\n",
      "\n",
      "================================================================================\n",
      "ElasticNet - Performance Metrics\n",
      "================================================================================\n",
      "Training Set:\n",
      "  RMSE: 3.4338\n",
      "  MAE:  2.6903\n",
      "  R¬≤:   0.8037\n",
      "\n",
      "Test Set:\n",
      "  RMSE: 3.6486\n",
      "  MAE:  2.8082\n",
      "  R¬≤:   0.7856\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"Training ElasticNet...\")\n",
    "\n",
    "# Extensive hyperparameter grid\n",
    "elasticnet_params = {\n",
    "    'alpha': [0.001, 0.01, 0.1, 0.5, 1.0, 5.0, 10.0, 50.0],\n",
    "    'l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9, 0.95, 0.99],\n",
    "    'selection': ['cyclic', 'random']\n",
    "}\n",
    "\n",
    "elasticnet = ElasticNet(random_state=R_seed, max_iter=10000)\n",
    "elasticnet_grid = GridSearchCV(\n",
    "    elasticnet, \n",
    "    elasticnet_params, \n",
    "    cv=kfold, \n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "elasticnet_grid.fit(X_train_linear, y_train_linear)\n",
    "\n",
    "print(f\"\\nBest parameters: {elasticnet_grid.best_params_}\")\n",
    "print(f\"Best CV RMSE: {-elasticnet_grid.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate\n",
    "elasticnet_best = elasticnet_grid.best_estimator_\n",
    "elasticnet_metrics = evaluate_model(\n",
    "    elasticnet_best, \n",
    "    X_train_linear, y_train_linear, \n",
    "    X_test_linear, y_test_linear,\n",
    "    'ElasticNet'\n",
    ")\n",
    "all_results.append(elasticnet_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a62d9e",
   "metadata": {},
   "source": [
    "---\n",
    "# Model 4: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed31997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest Regressor...\n",
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n",
      "\n",
      "Best parameters: {'bootstrap': False, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "Best CV RMSE: 3.2242\n",
      "\n",
      "================================================================================\n",
      "Random Forest - Performance Metrics\n",
      "================================================================================\n",
      "Training Set:\n",
      "  RMSE: 0.0000\n",
      "  MAE:  0.0000\n",
      "  R¬≤:   1.0000\n",
      "\n",
      "Test Set:\n",
      "  RMSE: 3.2527\n",
      "  MAE:  2.2860\n",
      "  R¬≤:   0.8296\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Random Forest Regressor...\")\n",
    "# Optimized hyperparameter grid (reduced for efficiency)\n",
    "rf_params = {\n",
    "    'n_estimators': [100, 300, 500],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=R_seed, n_jobs=-1)\n",
    "rf_grid = GridSearchCV(\n",
    "    rf, \n",
    "    rf_params, \n",
    "    cv=kfold, \n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "rf_grid.fit(X_train_tree, y_train_tree)\n",
    "\n",
    "print(f\"\\nBest parameters: {rf_grid.best_params_}\")\n",
    "print(f\"Best CV RMSE: {-rf_grid.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate\n",
    "rf_best = rf_grid.best_estimator_\n",
    "rf_metrics = evaluate_model(\n",
    "    rf_best, \n",
    "    X_train_tree, y_train_tree, \n",
    "    X_test_tree, y_test_tree,\n",
    "    'Random Forest'\n",
    ")\n",
    "all_results.append(rf_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450c9a25",
   "metadata": {},
   "source": [
    "---\n",
    "# Model 5: XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b89a1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost Regressor...\n",
      "Fitting 5 folds for each of 2916 candidates, totalling 14580 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 14580 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n14580 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\benje\\anaconda3\\Lib\\site-packages\\xgboost\\data.py\", line 407, in pandas_feature_info\n    new_feature_types.append(_pandas_dtype_mapper[dtype.name])\n                             ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 'object'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\benje\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\benje\\anaconda3\\Lib\\site-packages\\xgboost\\core.py\", line 774, in inner_f\n    return func(**kwargs)\n  File \"c:\\Users\\benje\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1343, in fit\n    train_dmatrix, evals = _wrap_evaluation_matrices(\n                           ~~~~~~~~~~~~~~~~~~~~~~~~~^\n        missing=self.missing,\n        ^^^^^^^^^^^^^^^^^^^^^\n    ...<14 lines>...\n        feature_types=feature_types,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\benje\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py\", line 702, in _wrap_evaluation_matrices\n    train_dmatrix = create_dmatrix(\n        data=X,\n    ...<9 lines>...\n        ref=None,\n    )\n  File \"c:\\Users\\benje\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1257, in _create_dmatrix\n    return QuantileDMatrix(\n        **kwargs, ref=ref, nthread=self.n_jobs, max_bin=self.max_bin\n    )\n  File \"c:\\Users\\benje\\anaconda3\\Lib\\site-packages\\xgboost\\core.py\", line 774, in inner_f\n    return func(**kwargs)\n  File \"c:\\Users\\benje\\anaconda3\\Lib\\site-packages\\xgboost\\core.py\", line 1768, in __init__\n    self._init(\n    ~~~~~~~~~~^\n        data,\n        ^^^^^\n    ...<12 lines>...\n        max_quantile_blocks=max_quantile_batches,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\benje\\anaconda3\\Lib\\site-packages\\xgboost\\core.py\", line 1832, in _init\n    it.reraise()\n    ~~~~~~~~~~^^\n  File \"c:\\Users\\benje\\anaconda3\\Lib\\site-packages\\xgboost\\core.py\", line 617, in reraise\n    raise exc  # pylint: disable=raising-bad-type\n    ^^^^^^^^^\n  File \"c:\\Users\\benje\\anaconda3\\Lib\\site-packages\\xgboost\\core.py\", line 598, in _handle_exception\n    return fn()\n  File \"c:\\Users\\benje\\anaconda3\\Lib\\site-packages\\xgboost\\core.py\", line 685, in <lambda>\n    return self._handle_exception(lambda: int(self.next(input_data)), 0)\n                                              ~~~~~~~~~^^^^^^^^^^^^\n  File \"c:\\Users\\benje\\anaconda3\\Lib\\site-packages\\xgboost\\data.py\", line 1632, in next\n    input_data(**self.kwargs)\n    ~~~~~~~~~~^^^^^^^^^^^^^^^\n  File \"c:\\Users\\benje\\anaconda3\\Lib\\site-packages\\xgboost\\core.py\", line 774, in inner_f\n    return func(**kwargs)\n  File \"c:\\Users\\benje\\anaconda3\\Lib\\site-packages\\xgboost\\core.py\", line 665, in input_data\n    new, feature_names, feature_types = _proxy_transform(\n                                        ~~~~~~~~~~~~~~~~^\n        data,\n        ^^^^^\n    ...<2 lines>...\n        self._enable_categorical,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\benje\\anaconda3\\Lib\\site-packages\\xgboost\\data.py\", line 1685, in _proxy_transform\n    df, feature_names, feature_types = _transform_pandas_df(\n                                       ~~~~~~~~~~~~~~~~~~~~^\n        data, enable_categorical, feature_names, feature_types\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\benje\\anaconda3\\Lib\\site-packages\\xgboost\\data.py\", line 662, in _transform_pandas_df\n    feature_names, feature_types = pandas_feature_info(\n                                   ~~~~~~~~~~~~~~~~~~~^\n        data, meta, feature_names, feature_types, enable_categorical\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\benje\\anaconda3\\Lib\\site-packages\\xgboost\\data.py\", line 409, in pandas_feature_info\n    _invalid_dataframe_dtype(data)\n    ~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n  File \"c:\\Users\\benje\\anaconda3\\Lib\\site-packages\\xgboost\\data.py\", line 372, in _invalid_dataframe_dtype\n    raise ValueError(msg)\nValueError: DataFrame.dtypes for data must be int, float, bool or category. When categorical type is supplied, the experimental DMatrix parameter`enable_categorical` must be set to `True`.  Invalid columns:BankruptcyHistory: object, HighUtilizationFlag: object, IsEndOfMonth: object, IsHighInterestLoan: object, OverleveragedFlag: object, PreviousLoanDefaults: object\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 29\u001b[0m\n\u001b[0;32m     14\u001b[0m xgb_model \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mXGBRegressor(\n\u001b[0;32m     15\u001b[0m     random_state\u001b[38;5;241m=\u001b[39mR_seed,\n\u001b[0;32m     16\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     17\u001b[0m     tree_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhist\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     18\u001b[0m )\n\u001b[0;32m     20\u001b[0m xgb_grid \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[0;32m     21\u001b[0m     xgb_model, \n\u001b[0;32m     22\u001b[0m     xgb_params, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m     27\u001b[0m )\n\u001b[1;32m---> 29\u001b[0m xgb_grid\u001b[38;5;241m.\u001b[39mfit(X_train_tree, y_train_tree)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBest parameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mxgb_grid\u001b[38;5;241m.\u001b[39mbest_params_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest CV RMSE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m-\u001b[39mxgb_grid\u001b[38;5;241m.\u001b[39mbest_score_\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\benje\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\benje\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1024\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1018\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1019\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1020\u001b[0m     )\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1024\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1028\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\benje\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1571\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1570\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1571\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\benje\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1001\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    994\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[0;32m    995\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    996\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    997\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    998\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[0;32m    999\u001b[0m     )\n\u001b[1;32m-> 1001\u001b[0m _warn_or_raise_about_fit_failures(out, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_score)\n\u001b[0;32m   1003\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m   1004\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m   1005\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m   1006\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m   1007\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[1;32mc:\\Users\\benje\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:517\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    511\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    512\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    513\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    514\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    515\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    516\u001b[0m     )\n\u001b[1;32m--> 517\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    519\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    520\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    521\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    522\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    526\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    527\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 14580 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n14580 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\benje\\anaconda3\\Lib\\site-packages\\xgboost\\data.py\", line 407, in pandas_feature_info\n    new_feature_types.append(_pandas_dtype_mapper[dtype.name])\n                             ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 'object'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\benje\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\benje\\anaconda3\\Lib\\site-packages\\xgboost\\core.py\", line 774, in inner_f\n    return func(**kwargs)\n  File \"c:\\Users\\benje\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1343, in fit\n    train_dmatrix, evals = _wrap_evaluation_matrices(\n                           ~~~~~~~~~~~~~~~~~~~~~~~~~^\n        missing=self.missing,\n        ^^^^^^^^^^^^^^^^^^^^^\n    ...<14 lines>...\n        feature_types=feature_types,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\benje\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py\", line 702, in _wrap_evaluation_matrices\n    train_dmatrix = create_dmatrix(\n        data=X,\n    ...<9 lines>...\n        ref=None,\n    )\n  File \"c:\\Users\\benje\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1257, in _create_dmatrix\n    return QuantileDMatrix(\n        **kwargs, ref=ref, nthread=self.n_jobs, max_bin=self.max_bin\n    )\n  File \"c:\\Users\\benje\\anaconda3\\Lib\\site-packages\\xgboost\\core.py\", line 774, in inner_f\n    return func(**kwargs)\n  File \"c:\\Users\\benje\\anaconda3\\Lib\\site-packages\\xgboost\\core.py\", line 1768, in __init__\n    self._init(\n    ~~~~~~~~~~^\n        data,\n        ^^^^^\n    ...<12 lines>...\n        max_quantile_blocks=max_quantile_batches,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\benje\\anaconda3\\Lib\\site-packages\\xgboost\\core.py\", line 1832, in _init\n    it.reraise()\n    ~~~~~~~~~~^^\n  File \"c:\\Users\\benje\\anaconda3\\Lib\\site-packages\\xgboost\\core.py\", line 617, in reraise\n    raise exc  # pylint: disable=raising-bad-type\n    ^^^^^^^^^\n  File \"c:\\Users\\benje\\anaconda3\\Lib\\site-packages\\xgboost\\core.py\", line 598, in _handle_exception\n    return fn()\n  File \"c:\\Users\\benje\\anaconda3\\Lib\\site-packages\\xgboost\\core.py\", line 685, in <lambda>\n    return self._handle_exception(lambda: int(self.next(input_data)), 0)\n                                              ~~~~~~~~~^^^^^^^^^^^^\n  File \"c:\\Users\\benje\\anaconda3\\Lib\\site-packages\\xgboost\\data.py\", line 1632, in next\n    input_data(**self.kwargs)\n    ~~~~~~~~~~^^^^^^^^^^^^^^^\n  File \"c:\\Users\\benje\\anaconda3\\Lib\\site-packages\\xgboost\\core.py\", line 774, in inner_f\n    return func(**kwargs)\n  File \"c:\\Users\\benje\\anaconda3\\Lib\\site-packages\\xgboost\\core.py\", line 665, in input_data\n    new, feature_names, feature_types = _proxy_transform(\n                                        ~~~~~~~~~~~~~~~~^\n        data,\n        ^^^^^\n    ...<2 lines>...\n        self._enable_categorical,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\benje\\anaconda3\\Lib\\site-packages\\xgboost\\data.py\", line 1685, in _proxy_transform\n    df, feature_names, feature_types = _transform_pandas_df(\n                                       ~~~~~~~~~~~~~~~~~~~~^\n        data, enable_categorical, feature_names, feature_types\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\benje\\anaconda3\\Lib\\site-packages\\xgboost\\data.py\", line 662, in _transform_pandas_df\n    feature_names, feature_types = pandas_feature_info(\n                                   ~~~~~~~~~~~~~~~~~~~^\n        data, meta, feature_names, feature_types, enable_categorical\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\benje\\anaconda3\\Lib\\site-packages\\xgboost\\data.py\", line 409, in pandas_feature_info\n    _invalid_dataframe_dtype(data)\n    ~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n  File \"c:\\Users\\benje\\anaconda3\\Lib\\site-packages\\xgboost\\data.py\", line 372, in _invalid_dataframe_dtype\n    raise ValueError(msg)\nValueError: DataFrame.dtypes for data must be int, float, bool or category. When categorical type is supplied, the experimental DMatrix parameter`enable_categorical` must be set to `True`.  Invalid columns:BankruptcyHistory: object, HighUtilizationFlag: object, IsEndOfMonth: object, IsHighInterestLoan: object, OverleveragedFlag: object, PreviousLoanDefaults: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Training XGBoost Regressor...\")\n",
    "\n",
    "# Optimized hyperparameter grid (reduced for efficiency)\n",
    "xgb_params = {\n",
    "    'n_estimators': [100, 300, 500],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'subsample': [0.7, 0.8, 0.9],\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'gamma': [0, 0.1, 0.3]\n",
    "}\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    random_state=R_seed,\n",
    "    n_jobs=-1,\n",
    "    tree_method='hist'\n",
    ")\n",
    "\n",
    "xgb_grid = GridSearchCV(\n",
    "    xgb_model, \n",
    "    xgb_params, \n",
    "    cv=kfold, \n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "xgb_grid.fit(X_train_tree, y_train_tree)\n",
    "\n",
    "print(f\"\\nBest parameters: {xgb_grid.best_params_}\")\n",
    "print(f\"Best CV RMSE: {-xgb_grid.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate\n",
    "xgb_best = xgb_grid.best_estimator_\n",
    "xgb_metrics = evaluate_model(\n",
    "    xgb_best, \n",
    "    X_train_tree, y_train_tree, \n",
    "    X_test_tree, y_test_tree,\n",
    "    'XGBoost'\n",
    ")\n",
    "all_results.append(xgb_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0494a4ed",
   "metadata": {},
   "source": [
    "---\n",
    "# Model 6: LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7924ba8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training LightGBM Regressor...\")\n",
    "\n",
    "# Optimized hyperparameter grid (reduced for efficiency)\n",
    "lgb_params = {\n",
    "    'n_estimators': [100, 300, 500],\n",
    "    'max_depth': [5, 7, 10, -1],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'num_leaves': [31, 63, 127],\n",
    "    'subsample': [0.7, 0.8, 0.9],\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9],\n",
    "    'min_child_samples': [10, 20],\n",
    "    'reg_alpha': [0, 0.1, 0.5],\n",
    "    'reg_lambda': [0, 0.1, 0.5]\n",
    "}\n",
    "\n",
    "lgb_model = lgb.LGBMRegressor(\n",
    "    random_state=R_seed,\n",
    "    n_jobs=-1,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "lgb_grid = GridSearchCV(\n",
    "    lgb_model, \n",
    "    lgb_params, \n",
    "    cv=kfold, \n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "lgb_grid.fit(X_train_tree, y_train_tree)\n",
    "\n",
    "print(f\"\\nBest parameters: {lgb_grid.best_params_}\")\n",
    "print(f\"Best CV RMSE: {-lgb_grid.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate\n",
    "lgb_best = lgb_grid.best_estimator_\n",
    "lgb_metrics = evaluate_model(\n",
    "    lgb_best, \n",
    "    X_train_tree, y_train_tree, \n",
    "    X_test_tree, y_test_tree,\n",
    "    'LightGBM'\n",
    ")\n",
    "all_results.append(lgb_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9bc98e",
   "metadata": {},
   "source": [
    "---\n",
    "# Model 7: CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43b8f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training CatBoost Regressor...\")\n",
    "\n",
    "# Optimized hyperparameter grid (reduced for efficiency)\n",
    "catboost_params = {\n",
    "    'iterations': [100, 300, 500],\n",
    "    'depth': [4, 6, 8, 10],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'l2_leaf_reg': [1, 3, 5],\n",
    "    'border_count': [64, 128],\n",
    "    'bagging_temperature': [0, 0.5, 1.0],\n",
    "    'random_strength': [1, 2]\n",
    "}\n",
    "\n",
    "catboost_model = CatBoostRegressor(\n",
    "    random_state=R_seed,\n",
    "    verbose=0,\n",
    "    thread_count=-1,\n",
    "    cat_features=cat_features_idx\n",
    ")\n",
    "\n",
    "catboost_grid = GridSearchCV(\n",
    "    catboost_model, \n",
    "    catboost_params, \n",
    "    cv=kfold, \n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=1,  # CatBoost handles parallelization internally\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "catboost_grid.fit(X_train_catboost, y_train_catboost)\n",
    "\n",
    "print(f\"\\nBest parameters: {catboost_grid.best_params_}\")\n",
    "print(f\"Best CV RMSE: {-catboost_grid.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate\n",
    "catboost_best = catboost_grid.best_estimator_\n",
    "catboost_metrics = evaluate_model(\n",
    "    catboost_best, \n",
    "    X_train_catboost, y_train_catboost, \n",
    "    X_test_catboost, y_test_catboost,\n",
    "    'CatBoost'\n",
    ")\n",
    "all_results.append(catboost_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61d3caa",
   "metadata": {},
   "source": [
    "---\n",
    "## Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf0f8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison dataframe\n",
    "results_df = pd.DataFrame(all_results)\n",
    "results_df = results_df.sort_values('Test RMSE')\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"COMPREHENSIVE MODEL COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nAll Models Ranked by Test RMSE:\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"BEST MODEL:\")\n",
    "print(\"=\" * 80)\n",
    "best_model = results_df.iloc[0]\n",
    "print(f\"\\nüèÜ {best_model['Model']}\")\n",
    "print(f\"   Test RMSE: {best_model['Test RMSE']:.4f}\")\n",
    "print(f\"   Test MAE:  {best_model['Test MAE']:.4f}\")\n",
    "print(f\"   Test R¬≤:   {best_model['Test R2']:.4f}\")\n",
    "print(f\"   Train RMSE: {best_model['Train RMSE']:.4f}\")\n",
    "print(f\"   Overfitting Gap: {best_model['Train RMSE'] - best_model['Test RMSE']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15af26de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. Test RMSE Comparison\n",
    "axes[0, 0].barh(results_df['Model'], results_df['Test RMSE'], color='steelblue')\n",
    "axes[0, 0].set_xlabel('RMSE')\n",
    "axes[0, 0].set_title('Test RMSE by Model (Lower is Better)')\n",
    "axes[0, 0].invert_yaxis()\n",
    "\n",
    "# 2. Test MAE Comparison\n",
    "axes[0, 1].barh(results_df['Model'], results_df['Test MAE'], color='coral')\n",
    "axes[0, 1].set_xlabel('MAE')\n",
    "axes[0, 1].set_title('Test MAE by Model (Lower is Better)')\n",
    "axes[0, 1].invert_yaxis()\n",
    "\n",
    "# 3. Test R¬≤ Comparison\n",
    "axes[1, 0].barh(results_df['Model'], results_df['Test R2'], color='seagreen')\n",
    "axes[1, 0].set_xlabel('R¬≤')\n",
    "axes[1, 0].set_title('Test R¬≤ by Model (Higher is Better)')\n",
    "axes[1, 0].invert_yaxis()\n",
    "\n",
    "# 4. Train vs Test RMSE (Overfitting Check)\n",
    "x = range(len(results_df))\n",
    "width = 0.35\n",
    "axes[1, 1].bar([i - width/2 for i in x], results_df['Train RMSE'], width, label='Train', color='lightblue')\n",
    "axes[1, 1].bar([i + width/2 for i in x], results_df['Test RMSE'], width, label='Test', color='darkblue')\n",
    "axes[1, 1].set_xlabel('Model')\n",
    "axes[1, 1].set_ylabel('RMSE')\n",
    "axes[1, 1].set_title('Train vs Test RMSE (Overfitting Check)')\n",
    "axes[1, 1].set_xticks(x)\n",
    "axes[1, 1].set_xticklabels(results_df['Model'], rotation=45, ha='right')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be42628",
   "metadata": {},
   "source": [
    "---\n",
    "## Save Best Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d67338",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create models directory if it doesn't exist\n",
    "models_dir = '../models'\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "# Save all trained models\n",
    "models_to_save = {\n",
    "    'ridge': ridge_grid,\n",
    "    'lasso': lasso_grid,\n",
    "    'elasticnet': elasticnet_grid,\n",
    "    'random_forest': rf_grid,\n",
    "    'xgboost': xgb_grid,\n",
    "    'lightgbm': lgbm_grid,\n",
    "    'catboost': catboost_grid\n",
    "}\n",
    "\n",
    "for model_name, model in models_to_save.items():\n",
    "    filepath = os.path.join(models_dir, f'{model_name}_best.pkl')\n",
    "    with open(filepath, 'wb') as f:\n",
    "        pickle.dump(model.best_estimator_, f)\n",
    "    print(f\"‚úì Saved {model_name} to {filepath}\")\n",
    "\n",
    "# Save the complete GridSearchCV objects (includes all hyperparameter search history)\n",
    "for model_name, model in models_to_save.items():\n",
    "    filepath = os.path.join(models_dir, f'{model_name}_gridsearch.pkl')\n",
    "    with open(filepath, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "    print(f\"‚úì Saved {model_name} GridSearch to {filepath}\")\n",
    "\n",
    "# Save the comparison results\n",
    "results_filepath = os.path.join(models_dir, 'model_comparison_results.csv')\n",
    "results_df.to_csv(results_filepath, index=False)\n",
    "print(f\"\\n‚úì Saved comparison results to {results_filepath}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"All models saved successfully!\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
